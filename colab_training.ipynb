{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33672aa6",
   "metadata": {},
   "source": [
    "# Seq2Seq Code Generation — Google Colab Training\n",
    "### Trains 3 models: Vanilla RNN | LSTM | Attention LSTM\n",
    "**Before running:** Go to `Runtime → Change runtime type → GPU (T4)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150e4717",
   "metadata": {},
   "source": [
    "## Step 1 — Upload Your Project Files\n",
    "Upload all `.py` files and `config_quick.yaml` from your local machine to Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Upload all project files at once\n",
    "# Select these files from your computer:\n",
    "# train.py, evaluate.py, visualize_attention.py, generate_report_plots.py,\n",
    "# data_loader.py, run.py, config_quick.yaml, requirements.txt\n",
    "# models/ folder files: __init__.py, vanilla_rnn.py, lstm.py, attention_lstm.py\n",
    "\n",
    "uploaded = files.upload()\n",
    "print(f\"Uploaded: {list(uploaded.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8761ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models/ directory and upload model files separately\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.chdir('models')\n",
    "print(\"Now upload the 4 model files: __init__.py, vanilla_rnn.py, lstm.py, attention_lstm.py\")\n",
    "model_files = files.upload()\n",
    "os.chdir('..')\n",
    "print(\"Model files uploaded:\", list(model_files.keys()))\n",
    "print(\"Current directory files:\", os.listdir('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed116f8",
   "metadata": {},
   "source": [
    "## Step 2 — Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09adfbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets sacrebleu seaborn pyyaml tqdm -q\n",
    "print(\"All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a51ae6",
   "metadata": {},
   "source": [
    "## Step 3 — Check GPU\n",
    "If you see \"No GPU\", go to `Runtime → Change runtime type → T4 GPU` and re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bacf8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(\"Training will be FAST on GPU!\")\n",
    "else:\n",
    "    print(\"No GPU found! Go to Runtime -> Change runtime type -> GPU\")\n",
    "    print(\"Training will be very slow on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85e40bd",
   "metadata": {},
   "source": [
    "## Step 4 — Set Config for Colab\n",
    "Writes the config file with 10k training examples, 5 epochs, GPU enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_config = \"\"\"\n",
    "dataset:\n",
    "  name: \"Nan-Do/code-search-net-python\"\n",
    "  train_size: 10000\n",
    "  val_size: 1000\n",
    "  test_size: 1000\n",
    "  max_docstring_length: 50\n",
    "  max_code_length: 80\n",
    "  cache_dir: \"./data_cache\"\n",
    "\n",
    "model:\n",
    "  embedding_dim: 256\n",
    "  hidden_dim: 256\n",
    "  dropout: 0.3\n",
    "  max_vocab_size: 10000\n",
    "\n",
    "training:\n",
    "  batch_size: 64\n",
    "  num_epochs: 5\n",
    "  learning_rate: 0.001\n",
    "  teacher_forcing_ratio: 0.5\n",
    "  gradient_clip: 5.0\n",
    "  save_every: 1\n",
    "\n",
    "paths:\n",
    "  checkpoints: \"./checkpoints\"\n",
    "  results: \"./results\"\n",
    "  visualizations: \"./visualizations\"\n",
    "  logs: \"./logs\"\n",
    "\n",
    "device: \"cuda\"\n",
    "\"\"\"\n",
    "\n",
    "with open('config_colab.yaml', 'w') as f:\n",
    "    f.write(colab_config.strip())\n",
    "\n",
    "print(\"config_colab.yaml created!\")\n",
    "print(\"Settings: 10k examples | 5 epochs | batch=64 | embedding=256 | hidden=256\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b228e9a2",
   "metadata": {},
   "source": [
    "## Step 5 — Train All 3 Models\n",
    "This will take approximately **30–60 minutes** on a T4 GPU.\n",
    "Progress bars will show loss for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326359d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --config config_colab.yaml --model all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a90c77",
   "metadata": {},
   "source": [
    "## Step 6 — Evaluate All Models\n",
    "Calculates BLEU score, Token Accuracy, and Exact Match on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluate.py --config config_colab.yaml --model all --split test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b12fc7",
   "metadata": {},
   "source": [
    "## Step 7 — Generate Attention Heatmaps & Report Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb26dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate attention heatmaps (5 examples + summary stats)\n",
    "!python visualize_attention.py --config config_colab.yaml --num_examples 5 --summary\n",
    "\n",
    "# Generate report plots (training curves, model comparison, performance by length)\n",
    "!python generate_report_plots.py --config config_colab.yaml\n",
    "\n",
    "# Show the attention heatmaps inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "viz_dir = './visualizations/attention'\n",
    "png_files = sorted([f for f in os.listdir(viz_dir) if f.endswith('.png')])\n",
    "\n",
    "print(f\"\\nFound {len(png_files)} visualization files:\")\n",
    "for f in png_files:\n",
    "    print(f\"  {f}\")\n",
    "\n",
    "# Display first 5 attention heatmaps\n",
    "fig, axes = plt.subplots(1, min(5, len(png_files)), figsize=(25, 6))\n",
    "if len(png_files) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, fname in enumerate(png_files[:5]):\n",
    "    img = mpimg.imread(os.path.join(viz_dir, fname))\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(fname.replace('.png', ''), fontsize=9)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf97c1",
   "metadata": {},
   "source": [
    "## Step 8 — Download Everything\n",
    "Downloads a single zip file containing: trained models, evaluation results, and all visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dda62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "def zip_folder(folder_path, zip_name):\n",
    "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "        for root, dirs, filenames in os.walk(folder_path):\n",
    "            for filename in filenames:\n",
    "                filepath = os.path.join(root, filename)\n",
    "                zf.write(filepath)\n",
    "    print(f\"Zipped: {zip_name} ({os.path.getsize(zip_name)/1e6:.1f} MB)\")\n",
    "\n",
    "# Zip checkpoints (trained model weights)\n",
    "zip_folder('./checkpoints', 'checkpoints.zip')\n",
    "\n",
    "# Zip results (BLEU scores, evaluation JSON files, plots)\n",
    "zip_folder('./results', 'results.zip')\n",
    "\n",
    "# Zip visualizations (attention heatmaps)\n",
    "zip_folder('./visualizations', 'visualizations.zip')\n",
    "\n",
    "# Download all 3 zips to your computer\n",
    "print(\"\\nDownloading files...\")\n",
    "files.download('checkpoints.zip')\n",
    "files.download('results.zip')\n",
    "files.download('visualizations.zip')\n",
    "print(\"Done! Check your Downloads folder.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
