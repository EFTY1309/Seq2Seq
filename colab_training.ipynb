{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33672aa6",
   "metadata": {},
   "source": [
    "# Seq2Seq Code Generation — Google Colab Training\n",
    "### Trains 3 models: Vanilla RNN | LSTM | Attention LSTM\n",
    "**Before running:** Go to `Runtime → Change runtime type → GPU (T4)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150e4717",
   "metadata": {},
   "source": [
    "## Step 1 — Upload Your Project as a ZIP\n",
    "**Before running this cell:**\n",
    "1. Go to your project folder: `i:\\Desktop\\All folders\\semester-8\\ML\\seq2seq\\`\n",
    "2. Select these files/folders: `train.py`, `evaluate.py`, `visualize_attention.py`, `generate_report_plots.py`, `data_loader.py`, `requirements.txt`, and the entire `models/` folder\n",
    "3. Right-click → **Send to → Compressed (zipped) folder** → name it `seq2seq.zip`\n",
    "4. Then run this cell and upload that single zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os, zipfile\n",
    "\n",
    "# Upload the single zip file\n",
    "uploaded = files.upload()  # select seq2seq.zip\n",
    "\n",
    "# Extract it\n",
    "zip_name = list(uploaded.keys())[0]\n",
    "with zipfile.ZipFile(zip_name, 'r') as zf:\n",
    "    zf.extractall('.')\n",
    "\n",
    "print(\"\\nExtracted files:\")\n",
    "print(\"Root:\", os.listdir('.'))\n",
    "if os.path.exists('models'):\n",
    "    print(\"models/:\", os.listdir('models'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed116f8",
   "metadata": {},
   "source": [
    "## Step 2 — Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09adfbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets sacrebleu seaborn pyyaml tqdm -q\n",
    "print(\"All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a51ae6",
   "metadata": {},
   "source": [
    "## Step 3 — Check GPU\n",
    "If you see \"No GPU\", go to `Runtime → Change runtime type → T4 GPU` and re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bacf8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(\"Training will be FAST on GPU!\")\n",
    "else:\n",
    "    print(\"No GPU found! Go to Runtime -> Change runtime type -> GPU\")\n",
    "    print(\"Training will be very slow on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85e40bd",
   "metadata": {},
   "source": [
    "## Step 4 — Set Config for Colab\n",
    "Writes the config file with 10k training examples, 5 epochs, GPU enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_config = \"\"\"\n",
    "dataset:\n",
    "  name: \"Nan-Do/code-search-net-python\"\n",
    "  train_size: 10000\n",
    "  val_size: 1000\n",
    "  test_size: 1000\n",
    "  max_docstring_length: 50\n",
    "  max_code_length: 80\n",
    "  cache_dir: \"./data_cache\"\n",
    "\n",
    "model:\n",
    "  embedding_dim: 256\n",
    "  hidden_dim: 256\n",
    "  dropout: 0.3\n",
    "  max_vocab_size: 10000\n",
    "\n",
    "training:\n",
    "  batch_size: 64\n",
    "  num_epochs: 5\n",
    "  learning_rate: 0.001\n",
    "  teacher_forcing_ratio: 0.5\n",
    "  gradient_clip: 5.0\n",
    "  save_every: 1\n",
    "\n",
    "paths:\n",
    "  checkpoints: \"./checkpoints\"\n",
    "  results: \"./results\"\n",
    "  visualizations: \"./visualizations\"\n",
    "  logs: \"./logs\"\n",
    "\n",
    "device: \"cuda\"\n",
    "\"\"\"\n",
    "\n",
    "with open('config_colab.yaml', 'w') as f:\n",
    "    f.write(colab_config.strip())\n",
    "\n",
    "print(\"config_colab.yaml created!\")\n",
    "print(\"Settings: 10k examples | 5 epochs | batch=64 | embedding=256 | hidden=256\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b228e9a2",
   "metadata": {},
   "source": [
    "## Step 5 — Train All 3 Models\n",
    "This will take approximately **30–60 minutes** on a T4 GPU.\n",
    "Progress bars will show loss for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326359d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --config config_colab.yaml --model all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a90c77",
   "metadata": {},
   "source": [
    "## Step 6 — Evaluate All Models\n",
    "Calculates BLEU score, Token Accuracy, and Exact Match on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluate.py --config config_colab.yaml --model all --split test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b12fc7",
   "metadata": {},
   "source": [
    "## Step 7 — Generate Attention Heatmaps & Report Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb26dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate attention heatmaps (5 examples + summary stats)\n",
    "!python visualize_attention.py --config config_colab.yaml --num_examples 5 --summary\n",
    "\n",
    "# Generate report plots (training curves, model comparison, performance by length)\n",
    "!python generate_report_plots.py --config config_colab.yaml\n",
    "\n",
    "# Show the attention heatmaps inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "viz_dir = './visualizations/attention'\n",
    "png_files = sorted([f for f in os.listdir(viz_dir) if f.endswith('.png')])\n",
    "\n",
    "print(f\"\\nFound {len(png_files)} visualization files:\")\n",
    "for f in png_files:\n",
    "    print(f\"  {f}\")\n",
    "\n",
    "# Display first 5 attention heatmaps\n",
    "fig, axes = plt.subplots(1, min(5, len(png_files)), figsize=(25, 6))\n",
    "if len(png_files) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, fname in enumerate(png_files[:5]):\n",
    "    img = mpimg.imread(os.path.join(viz_dir, fname))\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(fname.replace('.png', ''), fontsize=9)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf97c1",
   "metadata": {},
   "source": [
    "## Step 8 — Download Everything\n",
    "Downloads a single zip file containing: trained models, evaluation results, and all visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dda62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "def zip_folder(folder_path, zip_name):\n",
    "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "        for root, dirs, filenames in os.walk(folder_path):\n",
    "            for filename in filenames:\n",
    "                filepath = os.path.join(root, filename)\n",
    "                zf.write(filepath)\n",
    "    print(f\"Zipped: {zip_name} ({os.path.getsize(zip_name)/1e6:.1f} MB)\")\n",
    "\n",
    "# Zip checkpoints (trained model weights)\n",
    "zip_folder('./checkpoints', 'checkpoints.zip')\n",
    "\n",
    "# Zip results (BLEU scores, evaluation JSON files, plots)\n",
    "zip_folder('./results', 'results.zip')\n",
    "\n",
    "# Zip visualizations (attention heatmaps)\n",
    "zip_folder('./visualizations', 'visualizations.zip')\n",
    "\n",
    "# Download all 3 zips to your computer\n",
    "print(\"\\nDownloading files...\")\n",
    "files.download('checkpoints.zip')\n",
    "files.download('results.zip')\n",
    "files.download('visualizations.zip')\n",
    "print(\"Done! Check your Downloads folder.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
